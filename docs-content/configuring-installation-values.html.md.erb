---
title: Configuring Installation Values for Spring Cloud Data Flow for Kubernetes
owner: Spring Cloud Data Flow Release Engineering
---

This topic describes how to configure the Spring Cloud Data Flow for Kubernetes installation resources before deploying to the Kubernetes cluster.

Before proceeding, review the [Preparing to Install SCDF for Kubernetes](preparing-to-install-scdf-for-kubernetes.html) topic for details about:

* Preparing the Spring Cloud Data Flow for Kubernetes installation resources on your local workstation, and
* Installing required command-line tools

## <a id='overview'></a> Overview

There are a few concepts that drive how the configuration of Spring Cloud Data Flow for Kubernetes is performed.

* Support for multiple deployment environments
* Configuration of application properties
* Configuration of Kubernetes Resources
* Support for installation in an air-gapped environment

The following sections explain these concepts and the steps you need to take to configure them.


## <a id='support-for-multiple-environments'></a> Support for multiple deployment environments

The installation is based on the tool [Kustomize](https://kustomize.io) that allows you to customize Kubernetes resources by providing base resources files and patch files that modify the base resources to target different deployment environments.
Kustomize is built into the kubectl CLI.
The provided configuration files support a development and production environment.
The development environment is intended to quickly try Spring Cloud Data Flow for Kubernetes by provisioning a RabbitMQ message broker and Postresql database.


### <a id='directory-structure'></a> Directory Structure

The installation directory structure contains the following directories.

* `bin` - scripts for installing and installing to the development environment as well as a script for performing image relocation.
* `apps` - Kubernetes resource files and application configuration files to support deployment to multiple environments
* `services` - Kubernetes resources for deploying RabbitMQ and Postgresql fur use with the development environment

The apps directory contains the following folder structure based on Kustomize namving conventions

<pre>
.
├── apps
│   ├── data-flow
│   │   ├── images
│   │   ├── kustomize
│   │   │   ├── base
│   │   │   └── overlays
│   │   └── schemas
│   └── skipper
│       ├── images
│       ├── kustomize
│       │   ├── base
│       │   └── overlays
│       └── schemas
</pre>

There are two directories for each application that is part of Spring Cloud Data Flow for Kubernetes.
The first directory, data-flow, contains the Data Flow Server and the second directory contains the Skipper server.
Within each application directory there is the following directory structure

* `images` - location for container images that can be downloaded separately.
* `kustomize` - the directory containing Kubernetes and application configuration files for use with Kustomize.
* `schemas` - Database schemas that you can install manually if you do not want each server to install them upon startup.

The contents of the kustomize directory is shown below.
Edit files in this directory to configure the application and Kubernetes resources.

<pre>
.
├── base
│   ├── deployment.yaml
│   ├── kustomization.yaml
│   ├── role-binding.yaml
│   ├── roles.yaml
│   ├── service-account.yaml
│   └── service.yaml
└── overlays
    ├── dev
    │   ├── application.yaml
    │   ├── deployment-patch.yaml
    │   ├── kustomization.yaml
    │   └── service-patch.yaml
    └── production
        ├── application.yaml
        ├── deployment-patch.yaml
        ├── kustomization.yaml
        └── service-patch.yaml
</pre>

**Base**

The `base` directory contains kubernetes resource files with default configuration values that are then patched by files in the overlays directory.
The file `kustomization.yaml` references the other yaml files in that directory.

**Overlays**

There is a directory per deployment environment.
In this case `dev` and `production` environments.
In each directory there is a `kustomization.yaml` file that references the `kustomization.yaml` file in the base and adds additional patches to modify values unique to the target deployment environment.
You can also add additonal configuration in the `kustomization.yaml` to set the target namespace to deploy to add labels and name prefixes.  See the [kustomization documentation](https://github.com/kubernetes-sigs/kustomize/blob/master/docs/fields.md) for additional fields that can be configured in the kustomization.yaml file.


## <a id='configuration-steps'></a> Configuration Steps

The file `application.yaml` is a Spring Boot configuration file that you will edit to configure the Data Flow and Skipper server.
For example, you can configure `spring.datasource` properties or `spring.cloud.dataflow.features` properties.
The `deployment-patch.yaml` and `service-patch.yaml` files are where you will patch the base kubernetes resources with values appropriate for your target environment.
Examples of these fields are memory/cpu allocations and ingress configuration.


### <a id='ingress-resource-configuration'></a> Ingress Resource

You can modify the `ingress-patch.yaml` in `apps/ingress/kustomize/overlays/dev/` directory.
Modify the host field to provide the DNS name required for your Ingress Controller configuration.


### <a id='loadbalancer-configuration'></a> Load Balancer

If your Kubernetes cluster supports Kubernetes Services of type LoadBalancer, you may use that type of service to provision a load balancer using an Ingress Controller such as NGINX or Contour.

<p class="note">
  This option is recommended when deploying Spring Cloud Data Flow for Kubernetes to VMware Enterprise PKS on AWS, Azure, or GCP, or on vSphere with NSX-T container networking.
</p>
<p class="note warning">
  This option is <strong>not compatible</strong> with VMware Enterprise PKS to vSphere with Flannel container networking.
</p>

### <a id='security-configuration'></a> Security

Spring Cloud Data Flow and Skipper servers use the Spring Security library to configure Authentication and Authorization using OAuth 2.0 and OpenID Connect.
This lets you integrate Spring Cloud Data Flow into Single Sign On (SSO) environments.
To configure the servers changes must be made to each server's `application.yaml` configuration file.
The [Spring Cloud Data Flow Reference Guide's Security section](https://docs.spring.io/spring-cloud-dataflow/docs/current/reference/htmlsingle/#configuration-local-security) provides the overall introduction of how to configure the Data Flow Server and the [Spring Cloud Data Flow Reference Gude's Azure section](https://docs.spring.io/spring-cloud-dataflow/docs/current/reference/htmlsingle/#appendix-identity-provider-azure) provides the instructions for configuration with Azure AD.
While the documentation is in the Spring Cloud Data Flow reference guide, the same steps must be take for the configuration of Skipper's `application.yaml` file.

### <a id='container-registry'></a> Container Registry

The Data Flow server displays Spring Boot application metadata that is stored as a label in the container image.
To retrieve that metadata configure the Data Flow server to access the container registry for the application images you will be deploying.
The section in the `application.yaml` file where this configuration goes is under the root

```
spring:
  cloud:
    dataflow:
      container:
        registry-configurations:
```
The examples of how to configure this section for Docker Hub, Artifactory/JFrog, Amazon Elastic Container Registry, Azure Container Registry, and the Harbor registry are in [Spring Cloud Data Flow Reference Guide's Container Metadata section](https://dataflow.spring.io/docs/feature-guides/general/application-metadata/#using-metadata-container-image-labels)


### <a id='monitoring'></a> Monitoring
In order to support both short live and long lived application monitoring, task and stream applications deployed Data Flow and Skipper can use the [Prometheus RSocket Proxy](https://github.com/micrometer-metrics/prometheus-rsocket-proxy).
Other monitoring technologies that use the Micrometer library are supported as well but their configuration will be different than the example shown below.
The Data Flow Dashboard provides a convenient link to custom [Stream and Task Grafana dashboards](https://github.com/spring-cloud/spring-cloud-dataflow/tree/master/src/grafana/prometheus/docker/grafana) that you can install into your Grafana server.


As an example of configuring monitoring for all deployed tasks and stream applications using Prometheus via an RSocket gateway, the following section in Data Flow's `application.yaml` should be configured.

```
spring:
  cloud:
    dataflow:
      applicationProperties:
        stream:
          management:
            metrics:
              export:
                prometheus:
                  enabled: true
                  rsocket:
                    enabled: true
                    host: prometheus-proxy
                    port: 7001
        task:
          management:
            metrics:
              export:
                prometheus:
                  enabled: true
                  rsocket:
                    enabled: true
                    host: prometheus-proxy
                    port: 7001
      grafana-info:
        url: 'https://grafana:3000'
```

The Grafana `url` should and Prometheus host/port values should be changed for you specific environment.
The Data Flow microsite contains more information on [stream monitoring](https://dataflow.spring.io/docs/feature-guides/streams/monitoring/#kubernetes) and [task monitoring](https://dataflow.spring.io/docs/feature-guides/batch/monitoring/#prometheus-1).

Since these common application properties are passed to the deployed task and stream applications, if you are using a different monitoring infrastrure that is supported by the micrometer library, you can set the appropriate Spring Boot configuration values for yoru monitoring infrastructure underneath the `applicationProperties.stream` and `applicationProperties.task` sections above.


## <a id='configure-app-registry-values'></a> Next: Configure App Registry Values

Spring Cloud Data Flow for Kubernetes depends on an external image registry to store the images it builds for buildpack-based applications. Proceed to the [Configuring the Application Image Registry](configuring-app-image-registry.html) topic for details on configuring Harbor, GCR, or Dockerhub as this registry for the installation.